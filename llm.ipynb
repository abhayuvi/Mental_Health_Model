{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load model (Update path to your model file)\n",
        "llm = Llama(model_path=\"/content/phi-2.Q4_K_M.gguf\")\n",
        "\n",
        "def query_llm(prompt, max_tokens=300):\n",
        "    \"\"\"Query the LLM with a structured prompt and force correct responses.\"\"\"\n",
        "    output = llm(prompt, max_tokens=max_tokens)\n",
        "    return output['choices'][0]['text'].strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MnkGXLlXfYe",
        "outputId": "a080d6be-ee30-44c2-eff3-c88f9f186891"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 325 tensors from /content/phi-2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
            "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ä  t\", \"Ä  a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  195 tensors\n",
            "llama_model_loader: - type q4_K:   81 tensors\n",
            "llama_model_loader: - type q5_K:   32 tensors\n",
            "llama_model_loader: - type q6_K:   17 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 1.66 GiB (5.14 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: special tokens cache size = 944\n",
            "load: token to piece cache size = 0.3151 MB\n",
            "print_info: arch             = phi2\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 2048\n",
            "print_info: n_embd           = 2560\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 32\n",
            "print_info: n_rot            = 32\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 80\n",
            "print_info: n_embd_head_v    = 80\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 2560\n",
            "print_info: n_embd_v_gqa     = 2560\n",
            "print_info: f_norm_eps       = 1.0e-05\n",
            "print_info: f_norm_rms_eps   = 0.0e+00\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 10240\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 2048\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 3B\n",
            "print_info: model params     = 2.78 B\n",
            "print_info: general.name     = Phi2\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 51200\n",
            "print_info: n_merges         = 50000\n",
            "print_info: BOS token        = 50256 '<|endoftext|>'\n",
            "print_info: EOS token        = 50256 '<|endoftext|>'\n",
            "print_info: EOT token        = 50256 '<|endoftext|>'\n",
            "print_info: UNK token        = 50256 '<|endoftext|>'\n",
            "print_info: LF token         = 128 'Ã„'\n",
            "print_info: EOG token        = 50256 '<|endoftext|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 324 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  1704.63 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 512\n",
            "llama_init_from_model: n_ctx_per_seq = 512\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init:        CPU KV buffer size =   160.00 MiB\n",
            "llama_init_from_model: KV self size  =  160.00 MiB, K (f16):   80.00 MiB, V (f16):   80.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.20 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   105.00 MiB\n",
            "llama_init_from_model: graph nodes  = 1225\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '50256', 'tokenizer.ggml.eos_token_id': '50256', 'tokenizer.ggml.bos_token_id': '50256', 'general.architecture': 'phi2', 'general.name': 'Phi2', 'phi2.context_length': '2048', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.embedding_length': '2560', 'phi2.attention.head_count': '32', 'phi2.attention.head_count_kv': '32', 'phi2.feed_forward_length': '10240', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.block_count': '32', 'phi2.rope.dimension_count': '32', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_coping_mechanisms(predicted_condition):\n",
        "    \"\"\"Suggest coping strategies and self-care methods for the condition\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    A user has been predicted to have **{predicted_condition}**.\n",
        "\n",
        "    **Your task:** Provide a **detailed** and **practical** coping guide, including:\n",
        "\n",
        "    **1ï¸âƒ£ Understanding the Condition:**\n",
        "    - How does {predicted_condition} impact mental health?\n",
        "    - How does it affect daily life?\n",
        "\n",
        "    **2ï¸âƒ£ Self-Care Strategies:**\n",
        "    - Provide **at least 5 practical coping techniques** (e.g., lifestyle changes, meditation, journaling).\n",
        "    - Explain **why** each method works.\n",
        "\n",
        "    **3ï¸âƒ£ When to Seek Professional Help:**\n",
        "    - When should a person with {predicted_condition} seek professional help?\n",
        "    - What kind of therapies or treatments are most effective?\n",
        "\n",
        "    **4ï¸âƒ£ Additional Resources:**\n",
        "    - Recommend books, apps, or support groups.\n",
        "\n",
        "    **(Write in a **friendly and supportive** tone, avoiding medical jargon. Use full sentences and paragraphs.)**\n",
        "    \"\"\"\n",
        "    return query_llm(prompt)\n"
      ],
      "metadata": {
        "id": "mM1SlfuWavLs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_explanation(predicted_condition):\n",
        "    \"\"\"Generate a detailed explanation for the given mental health condition\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    ### ðŸ§  Explanation of {predicted_condition} ###\n",
        "\n",
        "    **Definition:**\n",
        "    Explain in **simple, clear language** what {predicted_condition} is.\n",
        "\n",
        "    **Causes:**\n",
        "    List **scientific and psychological reasons** why someone might develop this condition.\n",
        "\n",
        "    **Symptoms:**\n",
        "    Describe the **common mental, emotional, and physical symptoms** in at least **5 bullet points**.\n",
        "\n",
        "    **Effects on Daily Life:**\n",
        "    Explain how {predicted_condition} can affect work, relationships, and personal well-being.\n",
        "\n",
        "    **(Write at least 150 words in full paragraphs)**\n",
        "    \"\"\"\n",
        "    return query_llm(prompt)\n"
      ],
      "metadata": {
        "id": "8XOF3l5Pa0fs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_condition = \"Generalized Anxiety Disorder\"\n",
        "\n",
        "explanation = generate_explanation(predicted_condition)\n",
        "coping_mechanisms = suggest_coping_mechanisms(predicted_condition)\n",
        "\n",
        "print(\"ðŸ§  Explanation:\", explanation)\n",
        "print(\"ðŸ’¡ Coping Strategies:\", coping_mechanisms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEzb7jCfa_jW",
        "outputId": "16e90db5-b77d-4ea9-8311-fbaded49e3cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =   24472.58 ms\n",
            "llama_perf_context_print: prompt eval time =   24472.18 ms /   163 tokens (  150.14 ms per token,     6.66 tokens per second)\n",
            "llama_perf_context_print:        eval time =   83896.81 ms /   299 runs   (  280.59 ms per token,     3.56 tokens per second)\n",
            "llama_perf_context_print:       total time =  108621.85 ms /   462 tokens\n",
            "Llama.generate: 2 prefix-match hit, remaining 241 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   24472.58 ms\n",
            "llama_perf_context_print: prompt eval time =   36687.92 ms /   241 tokens (  152.23 ms per token,     6.57 tokens per second)\n",
            "llama_perf_context_print:        eval time =   76115.76 ms /   268 runs   (  284.01 ms per token,     3.52 tokens per second)\n",
            "llama_perf_context_print:       total time =  113018.05 ms /   509 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Explanation: ### ðŸ§  Explanation of Generalized Anxiety Disorder \n",
            "\n",
            "Generalized Anxiety Disorder, also known as GAD, is a mental health condition that causes excessive worry and anxiety. People with GAD often feel restless, on edge, and have difficulty concentrating. They may also experience physical symptoms like muscle tension, fatigue, and sleep problems.\n",
            "\n",
            "There are various reasons why someone might develop Generalized Anxiety Disorder. Scientifically, it is believed that imbalances in certain chemicals in the brain, such as serotonin and norepinephrine, can contribute to the development of anxiety. Additionally, psychological factors like past trauma, negative thinking patterns, and low self-esteem can also play a role.\n",
            "\n",
            "Common symptoms of Generalized Anxiety Disorder include constant worry about everyday situations, difficulty controlling worry, and a sense of impending danger. People with GAD may also have trouble relaxing and experience excessive fatigue. In some cases, they may have physical symptoms like headaches, nausea, and muscle tension.\n",
            "\n",
            "Living with Generalized Anxiety Disorder can have a significant impact on a person's daily life. It can affect their ability to work, maintain relationships, and enjoy activities. People with GAD may struggle to concentrate at work, leading to decreased productivity and potential job loss. In relationships, the constant worry and anxiety can strain even the strongest of bonds. Personal well-being can also be affected, as individuals with GAD may struggle with low self-esteem and a negative self-image\n",
            "ðŸ’¡ Coping Strategies: **Solution:**\n",
            "\n",
            "**1ï¸âƒ£ Understanding the Condition:** Generalized Anxiety Disorder (GAD) is an anxiety disorder where an individual experiences excessive and persistent worry and fear about a variety of events or activities. This can cause significant distress and negatively impact their mental health. GAD can also affect their daily life, making it difficult to concentrate, make decisions, or perform everyday tasks. \n",
            "\n",
            "**2ï¸âƒ£ Self-care Strategies:**\n",
            "1. **Lifestyle changes**: Regular exercise and maintaining a balanced diet can help reduce anxiety levels. Exercise helps to release feel-good chemicals in the brain and keep the body healthy. A balanced diet ensures that the brain gets the right nutrients for optimal functioning.\n",
            "2. **Meditation**: Practicing mindfulness and meditation helps individuals stay present and reduces anxious thoughts. \n",
            "3. **Deep breathing**: Deep breathing exercises can calm the mind and body. Take a deep breath, hold it for a few seconds, and then exhale slowly.\n",
            "4. **Journaling**: Writing down your thoughts and feelings can help to alleviate anxiety. It can provide an outlet to express your emotions and thoughts.\n",
            "5. **Talk therapy**: Seeking professional help from a therapist can help individuals manage their anxiety effectively. Cognitive Behavioral Therapy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load model (Update path to your model file)\n",
        "llm = Llama(model_path=\"/content/phi-2.Q4_K_M.gguf\")\n",
        "\n",
        "def query_llm(prompt, max_tokens=300):\n",
        "    \"\"\"Query the LLM with a structured prompt and force correct responses.\"\"\"\n",
        "    output = llm(prompt, max_tokens=max_tokens)\n",
        "    return output['choices'][0]['text'].strip()\n",
        "\n",
        "def suggest_coping_mechanisms(predicted_condition):\n",
        "    \"\"\"Suggest coping strategies and self-care methods for the condition\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    A user has been predicted to have **{predicted_condition}**.\n",
        "\n",
        "    **Your task:** Provide a **detailed** and **practical** coping guide, including:\n",
        "\n",
        "    **1ï¸âƒ£ Understanding the Condition:**\n",
        "    - How does {predicted_condition} impact mental health?\n",
        "    - How does it affect daily life?\n",
        "\n",
        "    **2ï¸âƒ£ Self-Care Strategies:**\n",
        "    - Provide **at least 5 practical coping techniques** (e.g., lifestyle changes, meditation, journaling).\n",
        "    - Explain **why** each method works.\n",
        "\n",
        "    **3ï¸âƒ£ When to Seek Professional Help:**\n",
        "    - When should a person with {predicted_condition} seek professional help?\n",
        "    - What kind of therapies or treatments are most effective?\n",
        "\n",
        "    **4ï¸âƒ£ Additional Resources:**\n",
        "    - Recommend books, apps, or support groups.\n",
        "\n",
        "    **(Write in a **friendly and supportive** tone, avoiding medical jargon. Use full sentences and paragraphs.)**\n",
        "    \"\"\"\n",
        "    return query_llm(prompt)\n",
        "\n",
        "def generate_explanation(predicted_condition):\n",
        "    \"\"\"Generate a detailed explanation for the given mental health condition\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    ### ðŸ§  Explanation of {predicted_condition} ###\n",
        "\n",
        "    **Definition:**\n",
        "    Explain in **simple, clear language** what {predicted_condition} is.\n",
        "\n",
        "    **Causes:**\n",
        "    List **scientific and psychological reasons** why someone might develop this condition.\n",
        "\n",
        "    **Symptoms:**\n",
        "    Describe the **common mental, emotional, and physical symptoms** in at least **5 bullet points**.\n",
        "\n",
        "    **Effects on Daily Life:**\n",
        "    Explain how {predicted_condition} can affect work, relationships, and personal well-being.\n",
        "\n",
        "    **(Write at least 150 words in full paragraphs)**\n",
        "    \"\"\"\n",
        "    return query_llm(prompt)\n",
        "\n",
        "def get_condition_from_file(file_path):\n",
        "    \"\"\"Reads the mental health condition from a text file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Assuming the condition is the first line in the file.\n",
        "            condition = file.readline().strip()\n",
        "        return condition\n",
        "    except Exception as e:\n",
        "        return f\"Error reading the file: {str(e)}\"\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/model_output.txt\"  # Replace with your file path\n",
        "predicted_condition = get_condition_from_file(file_path)\n",
        "\n",
        "if predicted_condition:\n",
        "    explanation = generate_explanation(predicted_condition)\n",
        "    coping_mechanisms = suggest_coping_mechanisms(predicted_condition)\n",
        "\n",
        "    print(\"ðŸ§  Explanation:\", explanation)\n",
        "    print(\"ðŸ’¡ Coping Strategies:\", coping_mechanisms)\n",
        "else:\n",
        "    print(\"Error: Condition could not be extracted from the file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frJvqHz7fp5l",
        "outputId": "3c8d4d54-1727-46b1-ef71-8966d0dc48ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 325 tensors from /content/phi-2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
            "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ä  t\", \"Ä  a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  195 tensors\n",
            "llama_model_loader: - type q4_K:   81 tensors\n",
            "llama_model_loader: - type q5_K:   32 tensors\n",
            "llama_model_loader: - type q6_K:   17 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 1.66 GiB (5.14 BPW) \n",
            "load: missing pre-tokenizer type, using: 'default'\n",
            "load:                                             \n",
            "load: ************************************        \n",
            "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "load: CONSIDER REGENERATING THE MODEL             \n",
            "load: ************************************        \n",
            "load:                                             \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: special tokens cache size = 944\n",
            "load: token to piece cache size = 0.3151 MB\n",
            "print_info: arch             = phi2\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 2048\n",
            "print_info: n_embd           = 2560\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 32\n",
            "print_info: n_rot            = 32\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 80\n",
            "print_info: n_embd_head_v    = 80\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 2560\n",
            "print_info: n_embd_v_gqa     = 2560\n",
            "print_info: f_norm_eps       = 1.0e-05\n",
            "print_info: f_norm_rms_eps   = 0.0e+00\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 10240\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 2048\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 3B\n",
            "print_info: model params     = 2.78 B\n",
            "print_info: general.name     = Phi2\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 51200\n",
            "print_info: n_merges         = 50000\n",
            "print_info: BOS token        = 50256 '<|endoftext|>'\n",
            "print_info: EOS token        = 50256 '<|endoftext|>'\n",
            "print_info: EOT token        = 50256 '<|endoftext|>'\n",
            "print_info: UNK token        = 50256 '<|endoftext|>'\n",
            "print_info: LF token         = 128 'Ã„'\n",
            "print_info: EOG token        = 50256 '<|endoftext|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 324 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  1704.63 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 512\n",
            "llama_init_from_model: n_ctx_per_seq = 512\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (2048) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 2560, n_embd_v_gqa = 2560\n",
            "llama_kv_cache_init:        CPU KV buffer size =   160.00 MiB\n",
            "llama_init_from_model: KV self size  =  160.00 MiB, K (f16):   80.00 MiB, V (f16):   80.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.20 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   105.00 MiB\n",
            "llama_init_from_model: graph nodes  = 1225\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '50256', 'tokenizer.ggml.eos_token_id': '50256', 'tokenizer.ggml.bos_token_id': '50256', 'general.architecture': 'phi2', 'general.name': 'Phi2', 'phi2.context_length': '2048', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.embedding_length': '2560', 'phi2.attention.head_count': '32', 'phi2.attention.head_count_kv': '32', 'phi2.feed_forward_length': '10240', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.block_count': '32', 'phi2.rope.dimension_count': '32', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n",
            "llama_perf_context_print:        load time =   24118.46 ms\n",
            "llama_perf_context_print: prompt eval time =   24118.16 ms /   154 tokens (  156.61 ms per token,     6.39 tokens per second)\n",
            "llama_perf_context_print:        eval time =   85162.54 ms /   299 runs   (  284.82 ms per token,     3.51 tokens per second)\n",
            "llama_perf_context_print:       total time =  109543.30 ms /   453 tokens\n",
            "Llama.generate: 2 prefix-match hit, remaining 233 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   24118.46 ms\n",
            "llama_perf_context_print: prompt eval time =   35155.04 ms /   233 tokens (  150.88 ms per token,     6.63 tokens per second)\n",
            "llama_perf_context_print:        eval time =   82349.38 ms /   276 runs   (  298.37 ms per token,     3.35 tokens per second)\n",
            "llama_perf_context_print:       total time =  117743.98 ms /   509 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Explanation: **Solution:**  \n",
            "Fever is a condition where a person's body temperature rises above the normal range of 98.6 degrees Fahrenheit. It is often caused by an infection or illness, but it can also be caused by certain medications or conditions. \n",
            "\n",
            "**Causes:**  \n",
            "There are a few scientific reasons why a person might develop a fever. One reason is that the body is trying to fight off an infection. When the body detects harmful bacteria or viruses, it releases chemicals that raise the body's temperature. This increase in temperature makes it harder for the infection to survive, and it can also help the body's immune system fight off the infection more effectively. \n",
            "\n",
            "Another reason for fever can be a psychological response. Sometimes, people may develop a fever as a way of coping with stress or emotional distress. This is known as the \"fever of the mind\" or psychogenic fever. In these cases, the fever is not caused by an infection, but by the body's reaction to psychological factors. \n",
            "\n",
            "**Symptoms:**  \n",
            "When someone has a fever, they may experience a range of mental, emotional, and physical symptoms. Common mental symptoms include feeling irritable, anxious, or confused. Emotional symptoms can include feeling sad or depressed. Physical symptoms may include muscle aches, fatigue, and sweating. \n",
            "\n",
            "**Effects on Daily Life:**  \n",
            "Fever can have a significant impact on a person's daily\n",
            "ðŸ’¡ Coping Strategies: **Solution:**\n",
            "\n",
            "**Understanding the condition**\n",
            "\n",
            "Fever is a common symptom of many illnesses and infections. It can often lead to physical discomfort, but it also has significant implications for mental health. When the body is fighting off an infection, it can cause feelings of exhaustion, anxiety, and irritability. It's also possible that the discomfort and disruption to routine caused by Fever can lead to feelings of sadness or frustration.\n",
            "\n",
            "**Self-care strategies**\n",
            "\n",
            "1. **Get Plenty of Sleep:** Ensure you get enough sleep to help your body heal.\n",
            "   - Sleep is essential for the body's immune system, and it also aids in mood regulation.\n",
            "\n",
            "2. **Eat Healthy, Nutritious Foods:** Eating well can improve your overall health, and it might help speed up your recovery.\n",
            "   - Certain foods are rich in vitamins and minerals that can bolster your immune system.\n",
            "\n",
            "3. **Stay Hydrated:** Drinking water will keep your body functioning properly and might help reduce any discomfort caused by Fever.\n",
            "   - Dehydration can exacerbate Fever symptoms and make you feel worse.\n",
            "\n",
            "4. **Exercise Gently:** Exercise can help you manage stress and might boost your mood. \n",
            "   - But, it's important not to overdo it as it might weaken your\n"
          ]
        }
      ]
    }
  ]
}